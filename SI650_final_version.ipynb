{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SI650_final_version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leah-Wu/SI650/blob/main/SI650_final_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6FC0ePC7j3p"
      },
      "source": [
        "# Get raw data and set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1WU8mEBuvHB",
        "outputId": "c2ed5fb9-5053-4e70-ee8e-9cf824ff4a5e"
      },
      "source": [
        "!wget -nc http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
        "!wget -nc http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Electronics.json.gz\n",
        "!gzip -d reviews_Electronics_5.json.gz\n",
        "!gzip -d meta_Electronics.json.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-12 17:08:55--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 495854086 (473M) [application/x-gzip]\n",
            "Saving to: ‘reviews_Electronics_5.json.gz’\n",
            "\n",
            "reviews_Electronics 100%[===================>] 472.88M  9.00MB/s    in 60s     \n",
            "\n",
            "2020-12-12 17:09:55 (7.83 MB/s) - ‘reviews_Electronics_5.json.gz’ saved [495854086/495854086]\n",
            "\n",
            "--2020-12-12 17:09:55--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Electronics.json.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 186594679 (178M) [application/x-gzip]\n",
            "Saving to: ‘meta_Electronics.json.gz’\n",
            "\n",
            "meta_Electronics.js 100%[===================>] 177.95M  11.3MB/s    in 9.9s    \n",
            "\n",
            "2020-12-12 17:10:05 (18.0 MB/s) - ‘meta_Electronics.json.gz’ saved [186594679/186594679]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANaUT7pZQr96"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from gensim import corpora, models, similarities\n",
        "from nltk.corpus import stopwords\n",
        "from datetime import timedelta\n",
        "import re\n",
        "import datetime\n",
        "import nltk\n",
        "import pprint\n",
        "import nltk.data\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import json\n",
        "import sqlite3\n",
        "import ast\n",
        "\n",
        "from gensim import corpora, models, similarities\n",
        "from nltk.corpus import stopwords\n",
        "from datetime import timedelta\n",
        "import re\n",
        "import datetime\n",
        "import nltk\n",
        "import pprint\n",
        "import nltk.data\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import json\n",
        "import sqlite3\n",
        "import ast\n",
        "\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from textblob import TextBlob\n",
        "\n",
        "REMOVE_PUNCTUATION_TABLE = str.maketrans({x: None for x in string.punctuation})\n",
        "TOKENIZER = TreebankWordTokenizer()\n",
        "STEMMER = PorterStemmer()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxuVc6hhC-C7",
        "outputId": "b83fee3b-bcce-492d-aa8d-c906759b3751"
      },
      "source": [
        "pip install textblob"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAuK9HJ7RACQ",
        "outputId": "cdee5dde-78c1-4569-8fdd-65bcbdd91a8b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asqlziLZQ8-a"
      },
      "source": [
        "Load data from dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baASWh0GQ6xZ"
      },
      "source": [
        "reviews_Musical_Instruments_5 = pd.read_json('reviews_Electronics_5.json',lines=True)\n",
        "meta_list = []\n",
        "with open('meta_Electronics.json') as f:\n",
        "  for line in f.readlines():\n",
        "    line = json.dumps(ast.literal_eval(line))\n",
        "    d = json.loads(line)\n",
        "    if 'title' not in d:\n",
        "      continue\n",
        "    else:\n",
        "      title = d['title']\n",
        "      product_id = d['asin']\n",
        "      img_url = d['imUrl']\n",
        "  \n",
        "      meta = []\n",
        "      meta.append(product_id)\n",
        "      meta.append(title)\n",
        "      meta.append(img_url)\n",
        "      meta_list.append(meta)\n",
        "column_names = ['asin','title','image_url']\n",
        "meta = pd.DataFrame(meta_list, columns=column_names)\n",
        "entire_merged_df = reviews_Musical_Instruments_5[['asin','overall','reviewerID','reviewText']].merge(meta[['asin', 'title','image_url']], on='asin', how='inner')\n",
        "entire_merged_df['reviewText'] = entire_merged_df['reviewText'].str.lower()\n",
        "asin_review_df = entire_merged_df[['asin','reviewText']]\n",
        "product_dict = dict(zip(entire_merged_df.asin, entire_merged_df.title))\n",
        "product_dict =  {k: v.lower() for k, v in product_dict.items()}\n",
        "review_list=list(entire_merged_df['reviewText'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgxj91RsSwaE"
      },
      "source": [
        "main function here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSZYJWWbwK-j",
        "outputId": "41c2a5cc-b23e-4428-d843-4ae18118a143"
      },
      "source": [
        "entire_merged_df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1643686 entries, 0 to 1643685\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count    Dtype \n",
            "---  ------      --------------    ----- \n",
            " 0   asin        1643686 non-null  object\n",
            " 1   overall     1643686 non-null  int64 \n",
            " 2   reviewerID  1643686 non-null  object\n",
            " 3   reviewText  1643686 non-null  object\n",
            " 4   title       1643686 non-null  object\n",
            " 5   image_url   1643686 non-null  object\n",
            "dtypes: int64(1), object(5)\n",
            "memory usage: 87.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1eG4fwL8LbQ"
      },
      "source": [
        "# Main functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNWtq0NKRPMr"
      },
      "source": [
        "Get queried dataset and the list of reviewText lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmON8BXEcPBi"
      },
      "source": [
        "def get_review_list(query,entire_merged_df):\n",
        "  queried_df = entire_merged_df[entire_merged_df['title'].str.contains(query)]\n",
        "  review_list = list(queried_df['reviewText'])\n",
        "  return review_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63t-tLT2RUdM"
      },
      "source": [
        "def query_dataframe(query,entire_merged_df):\n",
        "  queried_df = entire_merged_df[entire_merged_df['title'].str.contains(query)]\n",
        "  #print(queried_df)\n",
        "  review_list = list(queried_df['reviewText'])\n",
        "  #print(review_list)\n",
        "  review_list_of_list = [[x] for x in review_list]\n",
        "\n",
        "  return review_list_of_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l361bmaiRb7b"
      },
      "source": [
        "Compute similarity and data preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgwDvrn7RZDH"
      },
      "source": [
        "def similarity(query, input):\n",
        "\n",
        "\tvalid_words = getdata([query])\n",
        "  \n",
        "\ttexts = []\n",
        "\tfor i in input:\n",
        "\t\ttexts.append(getdata(i))\n",
        "\n",
        "\tdictionary = corpora.Dictionary(texts)\n",
        "\n",
        "\tnew_xs = dictionary.doc2bow(valid_words)\n",
        "\tcorpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\t  \n",
        "\ttfidf = models.TfidfModel(corpus)\n",
        "\tfeaturenum = len(dictionary.token2id.keys())\n",
        "\tindex = similarities.SparseMatrixSimilarity(tfidf[corpus],\n",
        "\t                                          num_features=featurenum)\n",
        "\tsim = index[tfidf[new_xs]]\n",
        "\tsim_list = sim.tolist()\n",
        "\t#print(len(sim_list))\n",
        "  # print(len(sim_list))\n",
        "\treturn sim_list"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tWnSnQZRbAT"
      },
      "source": [
        "def getdata(texts):\n",
        "\ttextTokenized = [[word.lower() for word in word_tokenize(text)] for\n",
        "                    text in texts]\n",
        "\n",
        "\tenglishStopwords = stopwords.words('english')\n",
        "\n",
        "\ttextFilterStopwords = [\n",
        "      [word for word in text if not word in englishStopwords] for text in\n",
        "      textTokenized]\n",
        "\n",
        "\tenglishPunctuations = [',', '.', ':', ';', '?', '(', ')', '[', ']',\n",
        "                          '&', '!', '*', '@', '#', '$', '%', '<', '>',\n",
        "                          '=', '{', '}', '+', '\"', '-', '/', \"'\", '\"']\n",
        "\ttext_no_pun = [\n",
        "      [word for word in text if word not in englishPunctuations]\n",
        "      for text in textFilterStopwords]\n",
        "\n",
        "\tst = PorterStemmer()\n",
        "\ttextStemed = [[st.stem(word) for word in text] for text in text_no_pun]\n",
        "\tflattened = [val for sublist in textStemed for val in sublist]\n",
        "\treturn flattened"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqIhjsXzTECH"
      },
      "source": [
        "Get the result similarity dataframe without feedback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj5z0sieTFfr"
      },
      "source": [
        "def get_result_similarity_wtfeedback(sim_list, review_list_of_list):\n",
        "  result_index_list = [i for i, e in enumerate(sim_list) if e != 0]\n",
        "  result_sim_dict = {}\n",
        "  for index in result_index_list:\n",
        "    result_sim_dict[review_list_of_list[index][0]] = sim_list[index]\n",
        "  result_review_list = []\n",
        "  for index in result_index_list:\n",
        "    result_review_list.append(review_list_of_list[index])\n",
        "  result_sim_df = pd.DataFrame(list(result_sim_dict.items()),columns = ['reviewText','similarity']) \n",
        "\n",
        "  result_df = pd.DataFrame()\n",
        "  for review in result_review_list:\n",
        "    result_df = result_df.append(asin_review_df.loc[asin_review_df['reviewText'] == review[0]], ignore_index=True)\n",
        "  \n",
        "  pol = lambda x: TextBlob(x).sentiment.polarity\n",
        "  result_df['polarity'] = result_df['reviewText'].apply(pol)\n",
        "\n",
        "  result_sim_df = result_sim_df.merge(result_df, on='reviewText', how='inner')\n",
        "\n",
        "  return result_sim_df"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA8-xI2HUJlH"
      },
      "source": [
        "Add nearest neighbor feedback. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPN60ZKdc_5M"
      },
      "source": [
        "def tokenize_and_stem(s):\n",
        "    return [STEMMER.stem(t) for t \n",
        "            in TOKENIZER.tokenize(s.translate(REMOVE_PUNCTUATION_TABLE))]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGL_ViYlX6Dc"
      },
      "source": [
        "def nn_feedback(feedback, review_list, query, result_sim_df):\n",
        "  # print('*******')\n",
        "  # print(result_sim_df)\n",
        "  # print('*******')\n",
        "  feedback_queries = list(feedback.keys())\n",
        "\n",
        "  # feedback_query = feedback_queries[0]\n",
        "\n",
        "  # feedback_query_tokenized = TOKENIZER.tokenize(\n",
        "  #       feedback_query.translate(REMOVE_PUNCTUATION_TABLE)\n",
        "  #       )\n",
        "\n",
        "  vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, stop_words='english')\n",
        "  vectorizer.fit(review_list)\n",
        "\n",
        "  feedback_queries = list(feedback.keys())\n",
        "\n",
        "  similarity = cosine_similarity(vectorizer.transform([query]), \n",
        "                                vectorizer.transform(feedback_queries))\n",
        "  \n",
        "  #print(similarity)\n",
        "\n",
        "  feedback_max_similarity = np.amax(similarity)\n",
        "\n",
        "  #print(feedback_max_similarity)\n",
        "\n",
        "  max_idx = np.argmax(similarity)\n",
        "\n",
        "  feedback_queries[max_idx]\n",
        "\n",
        "  pos_feedback_product_id = [idx for idx, feedback_value \n",
        "                        in feedback[feedback_queries[max_idx]] \n",
        "                        if feedback_value == 1.]\n",
        "\n",
        "  counts = Counter(pos_feedback_product_id)\n",
        "\n",
        "  pos_feedback_proportions = {\n",
        "        doc_idx: count / sum(counts.values()) for doc_idx, count in counts.items()\n",
        "  }\n",
        "\n",
        "  pos_feedback_feature = {}\n",
        "  for key in pos_feedback_proportions:\n",
        "    pos_feedback_feature[key] = pos_feedback_proportions[key]*feedback_max_similarity\n",
        "  \n",
        "  for pid in pos_feedback_feature:\n",
        "    if pid not in result_sim_df.values:\n",
        "      result_sim_df = result_sim_df.append({'asin': pid, 'similarity':result_sim_df.get(pid)}, ignore_index=True)\n",
        "\n",
        "  result_sim_df = result_sim_df[result_sim_df.groupby('asin')['similarity'].transform('max') == result_sim_df['similarity']]\n",
        "  return result_sim_df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj_JwWWD7wdb"
      },
      "source": [
        "# help functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNo8EeyycxvS"
      },
      "source": [
        "def parse_query(query):\n",
        "  feature = \"\" \n",
        "  query_list = query.split(',')\n",
        "  #print(query_list)\n",
        "  count = 0\n",
        "  for ele in query_list:  \n",
        "    feature += ele\n",
        "    feature += ' '   \n",
        "  result_query_list = []\n",
        "  result_query_list.append(query_list[0])\n",
        "  result_query_list.append(feature)\n",
        "  #print(feature)\n",
        "  return result_query_list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdH1_IxySv7H"
      },
      "source": [
        "def get_result(query, entire_merged_df, feedback):\n",
        "  query_list = parse_query(query)\n",
        "  # print(query_list[0])\n",
        "  review_list_of_list = query_dataframe(query_list[0],entire_merged_df)\n",
        "  # review_list_of_list\n",
        "  # print(review_list_of_list)\n",
        "\n",
        "  review_list = get_review_list(query_list[0],entire_merged_df)\n",
        "  # print(query_list[1])\n",
        "  sim_list = similarity(query_list[1], review_list_of_list)\n",
        "  # print(sim_list)\n",
        "  result_sim_df = get_result_similarity_wtfeedback(sim_list, review_list_of_list)\n",
        "\n",
        "  result_max_sim_df = result_sim_df[result_sim_df.groupby('asin')['similarity'].transform('max') == result_sim_df['similarity']]\n",
        "  result_max_sim_df = result_max_sim_df[['asin', 'reviewText','similarity']]\n",
        "\n",
        "  #group by asin and use polarity\n",
        "  grouped_result_sim_df = result_sim_df.groupby(['asin'])['polarity'].sum()\n",
        "  grouped_result_sim_df = grouped_result_sim_df.reset_index()\n",
        "  grouped_result_sim_df = grouped_result_sim_df[grouped_result_sim_df.polarity > 0]\n",
        "\n",
        "  grouped_result_sim_df = grouped_result_sim_df.merge(result_max_sim_df, on='asin', how='inner')\n",
        "  # grouped_result_sim_df\n",
        "\n",
        "  result_sim_df = nn_feedback(feedback, review_list, query, grouped_result_sim_df)\n",
        "\n",
        "  result_sim_df = result_sim_df.sort_values(['similarity', 'polarity'], ascending=[False, False])\n",
        "  res_list = result_sim_df[\"asin\"].tolist()\n",
        "  return res_list[:10]\n",
        "# result_sim_df"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndiyEoRT-yBj"
      },
      "source": [
        "def update_cache(asin_rel_tuple, query, feedback):\n",
        "  result_query_list = parse_query(query)\n",
        "  query = result_query_list[1]\n",
        "  if query not in feedback:\n",
        "    feedback[query] = []\n",
        "  feedback[query].append(asin_rel_tuple)\n",
        "  return feedback"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9sNrxTE7bly"
      },
      "source": [
        "# Test given queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAFveQclCmhT"
      },
      "source": [
        "Get queries from github:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwWs7cwsCkoz",
        "outputId": "c295c292-ac4b-4660-fefd-94f41a3d49e5"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/Leah-Wu/SI650/main/review_data/test-queries.txt"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-12 01:29:18--  https://raw.githubusercontent.com/Leah-Wu/SI650/main/review_data/test-queries.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 601 [text/plain]\n",
            "Saving to: ‘test-queries.txt’\n",
            "\n",
            "\rtest-queries.txt      0%[                    ]       0  --.-KB/s               \rtest-queries.txt    100%[===================>]     601  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-12 01:29:18 (32.2 MB/s) - ‘test-queries.txt’ saved [601/601]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5GLuYVIDGN7",
        "outputId": "01e3030d-ee4b-44f8-aa24-36f5383529a6"
      },
      "source": [
        "query_list = []\n",
        "with open('test-queries.txt') as query_file:\n",
        "  for query_num, line in enumerate(query_file):\n",
        "    query_list.append((query_num + 1, line))\n",
        "print(query_list)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 'earphone,wireless,waterproof\\n'), (2, 'earphone,noise canceling,in ear\\n'), (3, 'headphone,light,long playtime\\n'), (4, 'laptop,windows,game friendly,slim\\n'), (5, 'laptop,student,affordable\\n'), (6, 'tablet,android,slim\\n'), (7, 'tablet,affordable,light-weight\\n'), (8, 'case,slim,magnetic\\n'), (9, 'watch,ftiness track,waterproof\\n'), (10, 'watch,long battery life,bluetooth\\n'), (11, 'monitor,slim,frameless,good picture quality\\n'), (12, 'speaker,blutooth,long battery life\\n'), (13, 'tv,smart,good picture quality\\n'), (14, 'projector,portable,good picture quality\\n'), (15, 'keyboard,wireless,backlight,smooth\\n'), (16, 'mouse,wireless,quiet\\n'), (17, 'printer,wireless,fast\\n'), (18, 'mount,stable,easy install,flexible\\n'), (19, 'lamp,portable,eye-caring,wireless\\n'), (20, 'phone,seamless,slim')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwQ0GEMIZlbh"
      },
      "source": [
        "feedback = {\n",
        "        'earphone wireless waterproof': [('B001GPCBPU', 1.)],\n",
        "        'piano keyboard': [('B0002F52EW', 1.)]\n",
        "}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB-Vn3jY5XZE",
        "outputId": "c0c17264-2ffe-4bac-c408-6668de1609ec"
      },
      "source": [
        "for q_id, query in query_list:\n",
        "  print(f\"Searching for query: {query}\")\n",
        "  curr_results = get_result(query, entire_merged_df, feedback)\n",
        "  for res in curr_results:\n",
        "    url=\"https://www.amazon.com/dp/\"+str(res)\n",
        "    final_res.append((q_id, res, url, query))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Searching for query: earphone,wireless,waterproof\n",
            "\n",
            "Searching for query: earphone,noise canceling,in ear\n",
            "\n",
            "Searching for query: headphone,light,long playtime\n",
            "\n",
            "Searching for query: laptop,windows,game friendly,slim\n",
            "\n",
            "Searching for query: laptop,student,affordable\n",
            "\n",
            "Searching for query: tablet,android,slim\n",
            "\n",
            "Searching for query: tablet,affordable,light-weight\n",
            "\n",
            "Searching for query: case,slim,magnetic\n",
            "\n",
            "Searching for query: watch,ftiness track,waterproof\n",
            "\n",
            "Searching for query: watch,long battery life,bluetooth\n",
            "\n",
            "Searching for query: monitor,slim,frameless,good picture quality\n",
            "\n",
            "Searching for query: speaker,blutooth,long battery life\n",
            "\n",
            "Searching for query: tv,smart,good picture quality\n",
            "\n",
            "Searching for query: projector,portable,good picture quality\n",
            "\n",
            "Searching for query: keyboard,wireless,backlight,smooth\n",
            "\n",
            "Searching for query: mouse,wireless,quiet\n",
            "\n",
            "Searching for query: printer,wireless,fast\n",
            "\n",
            "Searching for query: mount,stable,easy install,flexible\n",
            "\n",
            "Searching for query: lamp,portable,eye-caring,wireless\n",
            "\n",
            "Searching for query: phone,seamless,slim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YGtX9Bp3MuEI",
        "outputId": "b54ecd7e-493e-43dc-9b79-886c07014781"
      },
      "source": [
        "final_res_df = pd.DataFrame(final_res, columns=[\"queryid\",\"productid\",\"product_url\",\"query_text\"])\n",
        "final_res_df"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queryid</th>\n",
              "      <th>productid</th>\n",
              "      <th>product_url</th>\n",
              "      <th>query_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>B005X1Y7I2</td>\n",
              "      <td>https://www.amazon.com/dp/B005X1Y7I2</td>\n",
              "      <td>stick,bluetooth,good remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>B000065UDU</td>\n",
              "      <td>https://www.amazon.com/dp/B000065UDU</td>\n",
              "      <td>stick,bluetooth,good remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>B000JV3A20</td>\n",
              "      <td>https://www.amazon.com/dp/B000JV3A20</td>\n",
              "      <td>stick,bluetooth,good remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>B005GFXH6S</td>\n",
              "      <td>https://www.amazon.com/dp/B005GFXH6S</td>\n",
              "      <td>stick,bluetooth,good remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B007RDWF0Q</td>\n",
              "      <td>https://www.amazon.com/dp/B007RDWF0Q</td>\n",
              "      <td>stick,bluetooth,good remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>19</td>\n",
              "      <td>B000I3T3K2</td>\n",
              "      <td>https://www.amazon.com/dp/B000I3T3K2</td>\n",
              "      <td>modem,reliable,fast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>19</td>\n",
              "      <td>B00006HUAS</td>\n",
              "      <td>https://www.amazon.com/dp/B00006HUAS</td>\n",
              "      <td>modem,reliable,fast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>19</td>\n",
              "      <td>B003Y49TO2</td>\n",
              "      <td>https://www.amazon.com/dp/B003Y49TO2</td>\n",
              "      <td>modem,reliable,fast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>19</td>\n",
              "      <td>B005J8330W</td>\n",
              "      <td>https://www.amazon.com/dp/B005J8330W</td>\n",
              "      <td>modem,reliable,fast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>19</td>\n",
              "      <td>B00GP2HS3Y</td>\n",
              "      <td>https://www.amazon.com/dp/B00GP2HS3Y</td>\n",
              "      <td>modem,reliable,fast</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    queryid  ...                   query_text\n",
              "0         5  ...  stick,bluetooth,good remote\n",
              "1         5  ...  stick,bluetooth,good remote\n",
              "2         5  ...  stick,bluetooth,good remote\n",
              "3         5  ...  stick,bluetooth,good remote\n",
              "4         5  ...  stick,bluetooth,good remote\n",
              "..      ...  ...                          ...\n",
              "85       19  ...          modem,reliable,fast\n",
              "86       19  ...          modem,reliable,fast\n",
              "87       19  ...          modem,reliable,fast\n",
              "88       19  ...          modem,reliable,fast\n",
              "89       19  ...          modem,reliable,fast\n",
              "\n",
              "[90 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEe5XzDKg5I0"
      },
      "source": [
        "final_res_df.to_csv(\"main-results.csv\")"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ7Nws1z7-ZX"
      },
      "source": [
        "# Feedback test after annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nsTDp_SS8MB"
      },
      "source": [
        "After Annotation, update cache with annotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-FKp2eyTBeu",
        "outputId": "c3729d26-b9ed-4c86-aeb4-0b3e0712d89c"
      },
      "source": [
        "!wget -nc https://github.com/Leah-Wu/SI650/raw/main/main-results-annotation.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-12 17:17:38--  https://github.com/Leah-Wu/SI650/raw/main/main-results-annotation.csv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Leah-Wu/SI650/main/main-results-annotation.csv [following]\n",
            "--2020-12-12 17:17:38--  https://raw.githubusercontent.com/Leah-Wu/SI650/main/main-results-annotation.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17060 (17K) [text/plain]\n",
            "Saving to: ‘main-results-annotation.csv’\n",
            "\n",
            "main-results-annota 100%[===================>]  16.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-12 17:17:38 (158 MB/s) - ‘main-results-annotation.csv’ saved [17060/17060]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bCtuYiqTysJ",
        "outputId": "75201928-e0f0-4758-cd9e-075f38635c3c"
      },
      "source": [
        "annotation_df = pd.read_csv(\"main-results-annotation.csv\",encoding='utf-8')\n",
        "annotation_df.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   queryid      200 non-null    int64 \n",
            " 1   productid    200 non-null    object\n",
            " 2   product_url  200 non-null    object\n",
            " 3   query_text   200 non-null    object\n",
            " 4   relevance    200 non-null    int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 7.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nykD00IzBoeL"
      },
      "source": [
        "Befor feedback:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMTZ4jjuBoDG",
        "outputId": "baaaed7a-ec30-4230-e464-1352a43b72c4"
      },
      "source": [
        "simlilar_query = \"earphone,sweatproof,durable\"\n",
        "new_results = get_result(simlilar_query, entire_merged_df, feedback)\n",
        "res_list=[]\n",
        "for res in new_results:\n",
        "  url=\"https://www.amazon.com/dp/\"+str(res)\n",
        "  res_list.append((res, url, simlilar_query))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foXRVqx9Vu6Y"
      },
      "source": [
        "feedback={}\n",
        "for i in range(20):\n",
        "  q_id = i+1\n",
        "  curr_df = annotation_df[annotation_df['queryid']==q_id]\n",
        "  query = curr_df.iloc[1]['query_text']\n",
        "  pd_list = curr_df[\"productid\"].tolist()\n",
        "  rel_list = curr_df[\"relevance\"].tolist()\n",
        "  # list_of_rel = []\n",
        "  for j in range(10):\n",
        "    rel_tuple = (pd_list[j], rel_list[j])\n",
        "    # list_of_rel.append(rel_tuple)\n",
        "    feedback = update_cache(rel_tuple, query, feedback)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kagWjRVEAsNH",
        "outputId": "15477650-f7c9-4e7c-e674-66082acebe24"
      },
      "source": [
        "print(feedback)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'earphone wireless waterproof\\n ': [('B00275F2GS', 0), ('B0036J1S1W', 1), ('B004CHHLDG', 0), ('B001GPCBPU', 0), ('B001I1A5WS', 0), ('B001GUPEMW', 1), ('B0051RW1SQ', 0), ('B005J0RAI6', 0), ('B005J0W3F6', 0), ('B003DW4A76', 0)], 'earphone noise canceling in ear\\n ': [('B001GPCBPU', 0), ('B007BWCDYQ', 0), ('B00029U0YK', 0), ('B00275F2GS', 0), ('B0036J1S1W', 0), ('B005J0W3F6', 1), ('B005J0RAI6', 1), ('B001GUPEMW', 1), ('B005IZ65G0', 1), ('B001I1A5WS', 1)], 'headphone light long playtime\\n ': [('B008LSUY7W', 0), ('B00113XADE', 0), ('B00478O0JI', 1), ('B0009MFKDQ', 1), ('B002VPDOH8', 0), ('B003BRNZTM', 0), ('B0036RDVU0', 1), ('B00CXP4AS8', 1), ('B0033ZP5YA', 0), ('B0036RA4CS', 1)], 'laptop windows game friendly slim\\n ': [('B004VC3NM0', 1), ('B00D4OF6SK', 1), ('B001KV0Z5I', 0), ('B008C3DEXM', 0), ('B005E99A8K', 0), ('B008F1GFWI', 0), ('B00763W9H6', 0), ('B0023XKUHA', 0), ('B009Z7NE1Q', 1), ('B002I2RHXQ', 0)], 'stick bluetooth good remote ': [('B005X1Y7I2', 0), ('B000065UDU', 1), ('B000JV3A20', 1), ('B005GFXH6S', 1), ('B007RDWF0Q', 1), ('B0042F3K9W', 0), ('B00E0NRESE', 0), ('B005NF5NTK', 0), ('B004CJPS66', 0), ('B000JLK5PK', 0)], 'tablet android slim\\n ': [('B008YGKVBU', 1), ('B0082YEH8M', 1), ('B005PSLFGA', 1), ('B00INXO85O', 1), ('B005JN1AT8', 1), ('B00HC8BY4Y', 0), ('B008N1TU22', 1), ('B00GZNCP3G', 0), ('B00BQ5KHJW', 0), ('B008YMA7QS', 0)], 'tablet affordable light-weight\\n ': [('B0082YEH8M', 1), ('B004OA6VYQ', 0), ('B005PSLFGA', 1), ('B0087AUCSA', 1), ('B00FCU6NWM', 1), ('B00A6J4WHW', 0), ('B00COAGRFG', 0), ('B00A0M3MY4', 0), ('B00BVKFWGA', 0), ('B004HZGL66', 1)], 'case slim magnetic\\n ': [('B005ESY8VA', 0), ('B007PA1K84', 1), ('B008I33BAC', 1), ('B007B31IAK', 0), ('B007M58WWO', 1), ('B00FCU6NWM', 1), ('B006BDRT68', 1), ('B002KAMD9Y', 0), ('B005HMUSOO', 1), ('B005UTAU24', 0)], 'memory card affordable high speed ': [('B002N694A6', 1), ('B000HDQ2G6', 0), ('B002TQ6HT6', 1), ('B000HCGAFK', 1), ('B002OL80UK', 1), ('B002OWHZMI', 1), ('B003EGNUH2', 1), ('B000ICLQD0', 1), ('B003UGJFT8', 1), ('B002PLBP56', 1)], 'player bluetooth portable ': [('B005HMT7QY', 1), ('B004PEIAD6', 0), ('B000EC3GDC', 0), ('B001A5FH9S', 1), ('B00B95REMW', 1), ('B0063W923A', 1), ('B004IMEN7C', 0), ('B005FPT5DI', 1), ('B00H3JTT30', 1), ('B0031HG5XU', 1)], 'monitor slim frameless good picture quality\\n ': [('B006O6ADIS', 0), ('B003LNZ1L6', 0), ('B0030CE6C8', 1), ('B006I0KL6Y', 0), ('B003JLPWAK', 0), ('B0041I8UAO', 1), ('B00B7IPT6Y', 1), ('B000X6XMWY', 1), ('B004HH1MR2', 1), ('B00AIWFNUW', 0)], 'speaker blutooth long battery life\\n ': [('B005Z3GINK', 1), ('B00AI5T7AG', 0), ('B00AI5UOJ4', 0), ('B00FZWZYWM', 1), ('B009FPUBBE', 1), ('B00D42AESY', 1), ('B00313JD06', 1), ('B007XOQI4S', 1), ('B000BSOBG0', 1), ('B00AI5VWAY', 0)], 'tv smart good picture quality\\n ': [('B00C8ZGOKU', 0), ('B00DK0VBTQ', 0), ('B0091UHMHO', 0), ('B00DK7B8JC', 0), ('B002U6KT8U', 0), ('B000GIT002', 0), ('B0082ULKUE', 1), ('B004GMAAJY', 0), ('B005O3YS38', 0), ('B005QT59YW', 0)], 'keyboard quiet affordable ': [('B003NREDC8', 1), ('B001N7AFSG', 0), ('B008FUW1J0', 1), ('B004GTQNS4', 1), ('B001NJQ5PG', 0), ('B006B15PWU', 1), ('B00AXY9CF2', 1), ('B0055PYQU0', 0), ('B001NJTZUS', 0), ('B0043CG3QG', 1)], 'keyboard wireless backlight smooth\\n ': [('B004WQO9HI', 1), ('B0065UZMJ8', 1), ('B005HBWIYI', 1), ('B0055PYQU0', 0), ('B003NREDC8', 1), ('B003BRURLG', 1), ('B004CVHCO0', 1), ('B003BRURUW', 0), ('B0050M92CU', 0), ('B00AXY9CF2', 0)], 'mouse wireless quiet\\n ': [('B0000AOWW9', 1), ('B0055QL1DO', 0), ('B004WITQ9C', 0), ('B00004VX3T', 1), ('B00005TQ09', 1), ('B000GOUE7O', 1), ('B0000AOWW8', 1), ('B00013VHAS', 1), ('B00005TQ08', 1), ('B005EDAEZO', 0)], 'drive portable good quality ': [('B00D780NNQ', 1), ('B004RUTBIG', 0), ('B00FDUHD2K', 1), ('B006FNCWSY', 0), ('B00A84E4BO', 1), ('B007582KGM', 0), ('B008AL9VXI', 1), ('B001AN16QI', 0), ('B0012R9WHW', 1), ('B0027CEMW6', 1)], 'mount stable easy install flexible\\n ': [('B003HB6XPU', 1), ('B00A86QWN0', 0), ('B000DZRY9C', 0), ('B003WUBL0S', 1), ('B00167XD78', 1), ('B00077INZU', 0), ('B0040IWVBY', 1), ('B00008AWL2', 0), ('B00D30UX8I', 1), ('B00006B83A', 0)], 'modem reliable fast ': [('B00723KZTY', 1), ('B000ESN9HY', 0), ('B00008A6CC', 1), ('B003HS7YVU', 0), ('B0047106KC', 1), ('B000I3T3K2', 1), ('B00006HUAS', 0), ('B003Y49TO2', 0), ('B005J8330W', 1), ('B00GP2HS3Y', 1)], 'adapter safe stable ': [('B00KFAGCUM', 0), ('B002P6PBAQ', 1), ('B00BJPRI1Y', 1), ('B0067I4Z6O', 1), ('B007Q45EF4', 1), ('B00BQ4F9ZA', 0), ('B007P6FW64', 0), ('B00EXIUFC8', 0), ('B005Z5HT2M', 1), ('B00C4P8E3E', 0)]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiO1O1DrZU0p"
      },
      "source": [
        "Search for a similar query in cache and check for result's ndcg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx5ZioOyZftH",
        "outputId": "1635bd6b-75e2-42cd-a842-b9c5f1050354"
      },
      "source": [
        "# simlilar_query = \"earphone,sweatproof,durable\"\n",
        "new_results = get_result(simlilar_query, entire_merged_df, feedback)\n",
        "for res in new_results:\n",
        "  url=\"https://www.amazon.com/dp/\"+str(res)\n",
        "  res_list.append((res, url, simlilar_query))\n",
        "res_list_df = pd.DataFrame(res_list, columns=[\"productid\",\"product_url\",\"query_text\"])\n",
        "res_list_df.to_csv(\"feedback-retry.csv\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}